{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Pipeline \n",
    "The following Jupyter notebook is a detailed documentation of the software pipeline for pre-processing of RoboPol Data for use in classifying artifacts and stars in an image using a Convolutional Neural Network. Each stage of the pipeline has a code along with detailed documentation of its working and what each line of the code means. The following are the different stages of the pipeline from the beginning to the end:\n",
    "1. JSON File\n",
    "2. Search and Copy \n",
    "3. IRAF Imexamine \n",
    "4. Sextractor\n",
    "5. Sorting\n",
    "6. Extract Stars\n",
    "7. Extract Artifacts\n",
    "8. FITS to PNG\n",
    "9. Cutouts\n",
    "10. Convolutional Neural Network\n",
    "\n",
    "We will go through each stage in the above order. The structure of every code is in the form of a Python function. Except for the Convolutional Neural Network all other Python codes can be executed individually from the terminal without any input arguments. A substantial effort has been made to avoid making use of external Python libraries unless there is no other option such as the case when reading FITS files using astropy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON File\n",
    "\n",
    "A JSON file in Python stands for JavaScript Object Notation. It is used as a standard data interchange format mainly for transmitting data between a web application and a server. We will use this file mainly to store information of software paths of different files and other inputs that would be required for running the code. \n",
    "\n",
    "Following is the JSON File. \n",
    "\n",
    "'input_param' is a dictionary with keywords that would be used to get information required for the codes. Each keyword represents the name of a code in the pipeline. Following is a description of the keywords:\n",
    "\n",
    "1. search_copy:\n",
    "\n",
    "The first argument here is the path of the folder where we store the RoboPol Data.\n",
    "\n",
    "The second argument is the path of the folder where we want to store the images which contain artifacts. \n",
    "\n",
    "The third argument is the path of the textfile which has a list of images that we know have artifacts. \n",
    "\n",
    "\n",
    "2. sorting:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_param = {\"search_copy\": [\"/home/walop/Documents/data/\", \n",
    "                               \"./artifact_images\",\n",
    "                               \"/home/walop/Documents/bad_data.txt\"],\n",
    "\"sorting\": [\"./artifact_images/catalog/\",\n",
    "            \"./sorted/\"],\n",
    "\"extract_stars\": [\"./extract_stars/\",\n",
    "                  \"./sorted/\"],\n",
    "\"extract_artifacts\": [\"./extract_artifacts/\",\n",
    "                     \"./artifact_images/output_87.log\"],\n",
    "\"fits_to_png\": [\"./artifact_images/*.fits\",\n",
    "               \"./png/\"],\n",
    "\"cutout\": [\"./png/*.png\",\n",
    "          \"./extract_artifacts/\",\n",
    "          \"./extract_stars/\",\n",
    "          \"./cutout/reflection_training/\",\n",
    "          \"./cutout/star_training/\"],\n",
    "               \n",
    "\"cnn\": [\"./cutout/reflection_training/\",\n",
    "       \"./cutout/star_training/\",\n",
    "       \"./cutout/test/\"],\n",
    "\"testing_script\": [\"./artifact_images/catalog/\",\n",
    "                  \"./artifact_images/\"]\n",
    "\n",
    "}\n",
    "\n",
    "with open('input_param.json', 'w') as json_file:\n",
    "    json.dump(input_param, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Searching through directories of images for required images and copying them into a destination directory\n",
    "\n",
    "This is the first function that we execute. Before usage check the following:\n",
    "\n",
    "#### Inputs:\n",
    "1. Enter the paths of \n",
    "\n",
    "a) Folder that contains the RoboPol data \n",
    "\n",
    "b) Folder where we want to store the images containing artifacts \n",
    "\n",
    "c) Textfile which has a list of the names of the images which we know have artifacts \n",
    "\n",
    "in the search_copy keyword of the JSON File as described in the JSON section. \n",
    "\n",
    "\n",
    "#### Usage: \n",
    "In the terminal, go to the home directory and type :\n",
    "\n",
    "    python search_and_copy.py\n",
    "#### Assumptions:\n",
    "1. The first assumption is that each line in the text file has a part of the filename of the image without the extension. An example textfile is given with the name \"bad_data.txt\" \n",
    "2. The second assumption is that all images are contained in a directory which could have multiple subdirectories. This is common when you segregate data according to the date of observation into subdirectories.\n",
    "3. The final assumption is that the data are FITS files. \n",
    "\n",
    "The code has been made generic enough to be modified with very small modifications for images or files of different types. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "import json\n",
    "\n",
    "def search_and_copy():\n",
    "    json_file=open('input_param.json')\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    source=data['search_copy'][0] #path where original RoboPol data is stored\n",
    "    dest=data['search_copy'][1] #path where selected artifact images have to be kept ready\n",
    "    textfile=data['search_copy'][2] #path to the textfile containing the names of images having artifacts\n",
    "    \n",
    "    f=open(textfile,\"r\") #read the textfile\n",
    "    \n",
    "    lines=f.readlines() #store all lines in file in list \"lines\"    \n",
    "\n",
    "    for line in lines: \n",
    "        #go through every image name ('line') in the text file\n",
    "        for dirpath, dirnames, filenames in os.walk(source): \n",
    "            #walk through all subdirectories and files in them\n",
    "            \n",
    "            image=line #Why we store line in image is because we will be \n",
    "            #appending .fits to the line every iteration. Therefore, \n",
    "            #we don't want to keep appending .fits to lines already \n",
    "            #ending with .fits else it would become something like \n",
    "            #.fits.fits and so on\n",
    "            image=image.strip() #we strip the whitespace from each line\n",
    "            image=image+\".fits\" #we add a '.fits' extension to each line \n",
    "\n",
    "            #First, make a list of all those files in each directory \n",
    "            #that end with the given \"line\" (image name) in our \"bad_data.txt\" \n",
    "            #file. That is make a list of all those images in \n",
    "            #each directory which have the same name as that of the \n",
    "            #names in our \"bad_data.txt\" file.\n",
    "            #Then iterate through those found images in each directory. If they are\n",
    "            #not already in the destination directory copy them to destination\n",
    "            #and copy them to destination directory. \n",
    "\n",
    "            for foundfile in [fi for fi in filenames if image in fi]:\n",
    "                src=os.path.join(dirpath,foundfile) #store the path of the image in list 'src'\n",
    "                if not foundfile in os.listdir(dest):\n",
    "            \n",
    "                    copy(src,dest) #copy list 'src' to destination'dest' which can be a directory or a file\n",
    "#search_and_copy() #Uncomment this to run the code in Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRAF Imexamine\n",
    "\n",
    "In order to train our Convolutional Neural Network we need to identify the artifacts and label them. Therefore, we need to manually first open the images containing the artifacts and record the pixel coordinates of the center of those artifacts. The Image Reduction and Analysis Facility (IRAF) has a tool called imexamine that allows us to perform several image processing tasks. \n",
    "\n",
    "#### Steps:\n",
    "1. In IRAF, type epar imexamine and edit the following: \n",
    "   a) logfile - Enter the name of the output file that would contain the coordinates and pixel brightness of the center of the artifact\n",
    "   b) keeplog - change to yes if it is no. \n",
    "2. Go to the folder containing the artifact images (using cd command) and then type : \n",
    "        imexamine *.fits \n",
    "3. Hover the mouse over the approximate center of the artifact that is visible to your eyes and press x. You will see 3 things that are printed in the terminal: x coordinate, y coordinate, pixel brightness. The same will be stored in the output logfile as well.\n",
    "4. Press n to go to the next image and repeat step 3.\n",
    "5. To quit, press q\n",
    "\n",
    "\n",
    "#### Caution:\n",
    "1. Imexamine is a pretty old tool and we need to make sure that we perform the above steps just as they have been mentioned. For instance, if we press m instead of n, it will actually print some image statistics that cannot be removed from the file. In case that happens, be sure to record this on paper and then once the file is made go and remove those lines. \n",
    "2. Imexamine will loop through the images automatically and when it reaches the last image it will again go back to the first image. Therefore, record on paper which was the first image you started with so that you know when to press q. \n",
    "3. It happens quite often that we will again loop through the images from the beginning after the last image. If it does happen like that, go to the output file generated and remove the repeated logs from the end of the file. Note that each new image name is recorded in the output file beginning with the # symbol and a number encolsed in square brackets indicating the sequence number in the loop. That will help you identify if you repeated any of the starting images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'epar_imexamine.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8cc7bc0b56d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epar_imexamine.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0;32m-> 1186\u001b[0;31m                 metadata=metadata)\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'epar_imexamine.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='epar_imexamine.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
